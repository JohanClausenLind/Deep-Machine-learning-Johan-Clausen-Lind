# Week 20 - Resources

[:house: Main page](https://github.com/kokchun/Deep-learning-AI21)

## Video guides :video_camera:


## Lecture notes :book:


## Theory :book:
- [K, Q, V in attention - CrossValidated forum discussions](https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms)
- [Positional encoding in Transformers - Brownlee (2022) machinelearningmastery blog post](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)
- [Positional encoding - Kazemnejad (2019) blog post](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)

Research articles
- [Attention is all you need - Vaswani et. al. (2017)](https://arxiv.org/pdf/1706.03762.pdf)

## Exercises :running:
Work with the project
